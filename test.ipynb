{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(seq_lengths, max_len):\n",
    "    batch_size = seq_lengths.size(0)\n",
    "    mask = torch.arange(max_len).unsqueeze(0).repeat(batch_size, 1) < seq_lengths.unsqueeze(1)\n",
    "    return mask.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = create_mask( torch.LongTensor([3, 5, 2]), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 6])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape # (B, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.unsqueeze(-1) * mask.unsqueeze(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_sparsification(S, relative_threshold=0.5):\n",
    "    S_flatten = S.view(S.shape[0], -1)\n",
    "    sorted_S_flatten, _ = S_flatten.sort(dim=-1, descending=True)\n",
    "    num_edges = sorted_S_flatten.count_nonzero(-1)\n",
    "    to_keep_edge = torch.ceil(num_edges * relative_threshold).to(torch.long)\n",
    "    threshold_score = sorted_S_flatten[range(S_flatten.shape[0]), to_keep_edge]\n",
    "    A = (S_flatten > threshold_score.reshape(-1, 1)).to(torch.float32).reshape(S.shape)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = torch.tensor([[[1, 2, 4, 0],\n",
    "                    [0, 7, 9, 3],\n",
    "                    [2, 3, 0, 2],\n",
    "                    [2, 3, 0, 2]],\n",
    "                    \n",
    "                    [[0, 0, 0, 0],\n",
    "                    [4, 2, 3, 4],\n",
    "                    [2, 3, 8, 2],\n",
    "                    [2, 3, 8, 2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = graph_sparsification(adj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 1., 0.],\n",
       "         [0., 1., 1., 1.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 1., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [1., 0., 0., 1.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 1., 0.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, L, L = A.shape\n",
    "A_bool = (A > 0).float()\n",
    "A_bool = A_bool * (torch.ones(L, L)  - torch.eye(L)) + torch.eye(L) \n",
    "degrees = torch.sum(A_bool, dim=-1)\n",
    "D = torch.diag_embed(degrees)\n",
    "D_inv_sqrt = torch.diag_embed(torch.pow(degrees, -0.5))\n",
    "A = torch.matmul(torch.matmul(D_inv_sqrt, A_bool), D_inv_sqrt)\n",
    "# A = (A_bool / D) / D.transpose(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5000, 0.0000, 0.5000, 0.0000],\n",
       "         [0.0000, 0.3333, 0.4082, 0.4082],\n",
       "         [0.0000, 0.4082, 0.5000, 0.0000],\n",
       "         [0.0000, 0.4082, 0.0000, 0.5000]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5774, 0.3333, 0.0000, 0.4082],\n",
       "         [0.0000, 0.0000, 1.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.7071, 0.5000]]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3., 2., 2.],\n",
       "        [1., 3., 1., 2.]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "mask = torch.randn((3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor([[0, 1, 0, 1], \n",
    "                     [1, 0, 0, 1], \n",
    "                     [1, 1, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn((3, 4, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5856,  0.8895],\n",
       "         [ 0.5397,  0.1495],\n",
       "         [-0.1620, -1.3551],\n",
       "         [ 1.6799,  0.2898]],\n",
       "\n",
       "        [[ 0.7726,  0.5483],\n",
       "         [ 0.1684,  1.7168],\n",
       "         [ 1.4387, -1.1326],\n",
       "         [-0.2431,  1.0632]],\n",
       "\n",
       "        [[-0.1673, -0.7475],\n",
       "         [-1.3425, -0.8553],\n",
       "         [-1.7839,  1.1274],\n",
       "         [ 0.3538,  0.3980]]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_mask, sorted_mask_index = torch.sort(mask, dim=-1, descending=True)  # B*L -> B*L\n",
    "X = torch.gather(X, dim=1, index=sorted_mask_index.unsqueeze(-1).expand(-1, -1, X.size(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5856,  0.8895],\n",
       "         [ 0.5397,  0.1495],\n",
       "         [-0.1620, -1.3551],\n",
       "         [ 1.6799,  0.2898]],\n",
       "\n",
       "        [[ 0.7726,  0.5483],\n",
       "         [ 0.1684,  1.7168],\n",
       "         [ 1.4387, -1.1326],\n",
       "         [-0.2431,  1.0632]],\n",
       "\n",
       "        [[-0.1673, -0.7475],\n",
       "         [-1.3425, -0.8553],\n",
       "         [-1.7839,  1.1274],\n",
       "         [ 0.3538,  0.3980]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = sorted_mask\n",
    "reduced_sequence_length = torch.sum(mask, 1) #(bs, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_max_length = torch.arange(torch.max(reduced_sequence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:, to_max_length, :]\n",
    "mask = mask[:, to_max_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5856,  0.8895],\n",
       "         [ 0.5397,  0.1495]],\n",
       "\n",
       "        [[ 0.7726,  0.5483],\n",
       "         [ 0.1684,  1.7168]],\n",
       "\n",
       "        [[-0.1673, -0.7475],\n",
       "         [-1.3425, -0.8553]]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_step = 5\n",
    "seq_len = torch.tensor([3, 4, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.arange(max_step)[None, :] < seq_len[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True, False, False],\n",
       "        [ True,  True,  True,  True, False],\n",
       "        [ True,  True, False, False, False]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7198,  0.5123],\n",
       "         [-0.4916, -1.3961],\n",
       "         [ 1.0301,  0.0440],\n",
       "         [ 0.1436, -0.7570],\n",
       "         [-0.0789, -0.2011]],\n",
       "\n",
       "        [[-0.9736, -1.5427],\n",
       "         [ 0.2477, -1.1202],\n",
       "         [-1.4221, -0.3273],\n",
       "         [-2.5559,  1.3811],\n",
       "         [ 0.6052, -0.5862]],\n",
       "\n",
       "        [[ 2.3897, -0.4373],\n",
       "         [-0.3200,  2.3656],\n",
       "         [ 0.9912,  0.0768],\n",
       "         [-0.0712, -0.6074],\n",
       "         [ 0.0264, -0.4160]]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((3, 5, 2))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0301,  0.0440],\n",
       "        [-2.5559,  1.3811],\n",
       "        [-0.3200,  2.3656]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[range(x.shape[0]), seq_len-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7198,  0.5123],\n",
       "         [-0.4916, -1.3961],\n",
       "         [ 1.0301,  0.0440],\n",
       "         [ 0.1436, -0.7570],\n",
       "         [-0.0789, -0.2011]],\n",
       "\n",
       "        [[-0.9736, -1.5427],\n",
       "         [ 0.2477, -1.1202],\n",
       "         [-1.4221, -0.3273],\n",
       "         [-2.5559,  1.3811],\n",
       "         [ 0.6052, -0.5862]],\n",
       "\n",
       "        [[ 2.3897, -0.4373],\n",
       "         [-0.3200,  2.3656],\n",
       "         [ 0.9912,  0.0768],\n",
       "         [-0.0712, -0.6074],\n",
       "         [ 0.0264, -0.4160]]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor(3.0, requires_grad=True)\n",
    "b = torch.tensor(1.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.where(a > b, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_graph_dense(node_embeddings, k, device=None):\n",
    "    # time1 = time.time()\n",
    "    raw_graph = torch.mm(node_embeddings, node_embeddings.t())\n",
    "    values, indices = raw_graph.topk(k=k, dim=-1)\n",
    "    assert torch.max(indices) < raw_graph.shape[1]\n",
    "    mask = torch.zeros(raw_graph.shape).to(raw_graph.device)\n",
    "    mask[torch.arange(raw_graph.shape[0]).view(-1, 1), indices] = 1.\n",
    "    mask.requires_grad = False\n",
    "    sparse_graph = raw_graph * mask\n",
    "    # time2 = time.time()\n",
    "    # print(f'dense knn time: {time2 - time1} second')\n",
    "    return sparse_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embedding = torch.randn((4, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1291, -0.0000,  0.1428,  0.0000],\n",
       "        [-0.0000,  0.1976, -0.1022, -0.0000],\n",
       "        [ 0.1428, -0.0000,  0.1762,  0.0000],\n",
       "        [ 0.0871, -0.0000,  0.0844,  0.0000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_graph_dense(node_embedding, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(att_log_logit, training, temp=1):\n",
    "    if training:\n",
    "        random_noise = torch.empty_like(att_log_logit).uniform_(1e-10, 1 - 1e-10)\n",
    "        random_noise = torch.log(random_noise) - torch.log(1.0 - random_noise)\n",
    "        att_bern = ((att_log_logit + random_noise) / temp).sigmoid()\n",
    "    else:\n",
    "        att_bern = (att_log_logit).sigmoid()\n",
    "    return att_bern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3420, 0.2144, 1.2561, 0.8420],\n",
       "        [2.2793, 0.1255, 0.4976, 0.1684],\n",
       "        [1.3094, 0.0990, 0.6438, 0.2882],\n",
       "        [0.4883, 0.0616, 1.0262, 0.3365]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "A = torch.randn((4, 4)).abs()\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3672, 0.0640, 0.4295, 0.3185],\n",
       "        [0.6804, 0.0409, 0.1856, 0.0695],\n",
       "        [0.4477, 0.0369, 0.2751, 0.1362],\n",
       "        [0.1847, 0.0254, 0.4850, 0.1759]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degrees = torch.sum(A, dim=-1)\n",
    "D_inv_sqrt = torch.diag_embed(torch.pow(degrees, -0.5))\n",
    "A1 = torch.matmul(torch.matmul(D_inv_sqrt, A), D_inv_sqrt)\n",
    "A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.6545, 3.0708, 2.3405, 1.9126])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5231, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.5707, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.6537, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.7231]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_inv_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(adj, mode=\"sym\"):\n",
    "    if mode == \"sym\":\n",
    "        inv_sqrt_degree = 1. / \\\n",
    "                            (torch.sqrt(adj.sum(dim=1, keepdim=False)) + 1e-10)\n",
    "        return inv_sqrt_degree[:, None] * adj * inv_sqrt_degree[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3672, 0.0640, 0.4295, 0.3185],\n",
       "        [0.6804, 0.0409, 0.1856, 0.0695],\n",
       "        [0.4477, 0.0369, 0.2751, 0.1362],\n",
       "        [0.1847, 0.0254, 0.4850, 0.1759]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = torch.tensor([0.0003, 0.0002, 0.0002, 0.0002, 0.0000, 0.0000, 0.0002, 0.0000, 0.0002,\n",
    "        0.0002, 0.0000, 0.0001, 0.0002, 0.0000, 0.0002, 0.0002, 0.0002, 0.0002,\n",
    "        0.0000, 0.0000, 0.0002, 0.0003, 0.0000, 0.0002, 0.0000, 0.0002, 0.0002,\n",
    "        0.0000, 0.0002, 0.0002, 0.0002, 0.0000, 0.0000, 0.0002, 0.0000, 0.0002,\n",
    "        0.0000, 0.0002, 0.0002, 0.0000, 0.0002, 0.0002, 0.0000, 0.0000, 0.0002,\n",
    "        0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0000, 0.0002, 0.0001,\n",
    "        0.0002, 0.0000, 0.0002, 0.0002, 0.0000, 0.0002, 0.0000, 0.0002, 0.0000,\n",
    "        0.0002, 0.0000, 0.0003, 0.0002, 0.0000, 0.0002, 0.0000, 0.0002, 0.0002,\n",
    "        0.0003, 0.0002, 0.0002, 0.0002, 0.0002, 0.0003, 0.0000, 0.0002, 0.0002,\n",
    "        0.0003, 0.0000, 0.0003, 0.0002, 0.0000, 0.0000, 0.0002, 0.0002, 0.0003,\n",
    "        0.0000, 0.0000, 0.0002, 0.0000, 0.0000, 0.0002, 0.0002, 0.0002, 0.0002,\n",
    "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0002, 0.0002, 0.0002, 0.0000,\n",
    "        0.0003, 0.0000, 0.0002, 0.0000, 0.0000, 0.0000, 0.0002, 0.0000, 0.0000,\n",
    "        0.0002, 0.0002, 0.0002, 0.0000, 0.0002, 0.0001, 0.0000, 0.0000, 0.0000,\n",
    "        0.0000, 0.0002, 0.0000, 0.0002, 0.0000, 0.0002, 0.0000, 0.0000, 0.0000,\n",
    "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "        0.0000, 0.0000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9783,  0.1693],\n",
       "        [ 1.1213, -0.0492],\n",
       "        [-1.2739,  0.2494]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(3, 2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin  = nn.Linear(1, X.shape[-1], bias=False)\n",
    "weighted_tensor = lin(torch.ones(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fts = X * weighted_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5817,  0.0075],\n",
       "         [-0.6667, -0.0022],\n",
       "         [ 0.7575,  0.0111]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5946,  0.0444]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5817,  0.0075],\n",
       "        [-0.6667, -0.0022],\n",
       "        [ 0.7575,  0.0111]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.weight.reshape(1, -1) * X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_sparsification(S, relative_threshold=None, to_keep_edge=None):\n",
    "    # S (bs, max_step, max_step)\n",
    "    S_flatten = S.view(S.shape[0], -1) #(bs, max_step * max_step)\n",
    "    sorted_S_flatten, _ = S_flatten.sort(dim=-1, descending=True)\n",
    "    num_edges = sorted_S_flatten.count_nonzero(-1) #(bs, )\n",
    "    if relative_threshold:\n",
    "        to_keep_edge = torch.ceil(\n",
    "            num_edges * relative_threshold).to(torch.long)\n",
    "    threshold_score = sorted_S_flatten[range(\n",
    "        S_flatten.shape[0]), to_keep_edge] # (bs, )\n",
    "    A = (S_flatten > threshold_score.reshape(-1, 1)\n",
    "            ).float().reshape(S.shape) #(bs, max_step, max_step)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = torch.tensor([[[1, 2.0, 3.0, 0],\n",
    "                    [0, 4.0, 8, 6],\n",
    "                    [2, 7, 0, 5],\n",
    "                    [2, 9, 0, 10]],\n",
    "                    \n",
    "                    [[0, 0, 0, 0],\n",
    "                    [5, 4, 2, 6],\n",
    "                    [9, 1, 3, 7],\n",
    "                    [17, 3, 8, 23]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0.],\n",
       "         [0., 0., 1., 1.],\n",
       "         [0., 1., 0., 1.],\n",
       "         [0., 1., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [1., 0., 0., 1.],\n",
       "         [1., 0., 1., 1.]]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_sparsification(adj, relative_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fcn_net(layer_sizes=[80, 40]):\n",
    "    fc_layers = nn.Sequential()\n",
    "    layer_sizes = [160] + layer_sizes\n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        fc_layers.append(nn.Linear(layer_sizes[i], layer_sizes[i + 1]))\n",
    "        # nn.BatchNorm1d(layer_sizes[i + 1])\n",
    "        fc_layers.append(nn.BatchNorm1d(num_features=layer_sizes[i+1],\n",
    "                  \n",
    "                              momentum=0.95,\n",
    "                                        eps=0.0001))\n",
    "        fc_layers.append(nn.ReLU())\n",
    "    fc_layers.append(nn.Linear(layer_sizes[-1], 1))\n",
    "    return fc_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fcn_net(nn.Module):\n",
    "    def __init__(self, layer_sizes=[80, 40]):\n",
    "        super().__init__()\n",
    "        pre_size = 160\n",
    "        self.lin = []\n",
    "        self.bn = []\n",
    "        self.act = nn.ReLU()\n",
    "        for cur_size in layer_sizes:\n",
    "            self.lin.append(nn.Linear(pre_size, cur_size))\n",
    "            self.bn.append(nn.BatchNorm1d(num_features=cur_size,\n",
    "                                            momentum=0.95,\n",
    "                                            eps=0.0001))\n",
    "            pre_size = cur_size\n",
    "        self.out = nn.Linear(pre_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.lin)):\n",
    "            x = self.lin[i](x)\n",
    "            x = x.transpose(1, 2)\n",
    "            x = self.bn[i](x)\n",
    "            x = x.transpose(1, 2)\n",
    "            x = self.act(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = Fcn_net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn((2, 300, 160)) * 3.0 + 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = layers(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5245,  0.1437,  0.5624,  ..., -2.5712,  0.8055,  1.0378],\n",
       "        [ 0.0907, -2.0665,  1.0194,  ..., -2.4032,  0.4346,  0.0520],\n",
       "        [ 0.4680, -2.1957, -0.7792,  ..., -2.7512, -1.2171, -0.7632],\n",
       "        ...,\n",
       "        [ 1.3315, -1.2946,  2.3550,  ...,  0.4583,  0.6593, -0.3422],\n",
       "        [-0.2917, -2.1434,  1.1829,  ...,  1.2107,  0.5214, -0.2825],\n",
       "        [-0.5851,  1.0321, -1.4969,  ..., -0.6987, -0.5602,  0.2895]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.lin[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    layers.eval()\n",
    "    t = layers(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5245,  0.1437,  0.5624,  ..., -2.5712,  0.8055,  1.0378],\n",
       "        [ 0.0907, -2.0665,  1.0194,  ..., -2.4032,  0.4346,  0.0520],\n",
       "        [ 0.4680, -2.1957, -0.7792,  ..., -2.7512, -1.2171, -0.7632],\n",
       "        ...,\n",
       "        [ 1.3315, -1.2946,  2.3550,  ...,  0.4583,  0.6593, -0.3422],\n",
       "        [-0.2917, -2.1434,  1.1829,  ...,  1.2107,  0.5214, -0.2825],\n",
       "        [-0.5851,  1.0321, -1.4969,  ..., -0.6987, -0.5602,  0.2895]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.lin[0].weight.grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(seq_lengths, max_len):\n",
    "    batch_size = seq_lengths.size(0)\n",
    "    mask = torch.arange(max_len).to(seq_lengths.device).unsqueeze(0).repeat(\n",
    "        batch_size, 1) < seq_lengths.unsqueeze(1)\n",
    "    return mask.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = torch.tensor([2, 3, 4, 5, 7, 0, 8])\n",
    "max_len = 10\n",
    "create_mask(seq_length, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_sparsification(S, relative_threshold=None, to_keep_edge=None):\n",
    "    # \n",
    "    # S (bs, max_step, max_step)\n",
    "    # for each batch, reserve largets  (ratio * num_edge) , return mask \n",
    "    S_flatten = S.view(S.shape[0], -1) #(bs, max_step * max_step)\n",
    "    sorted_S_flatten, _ = S_flatten.sort(dim=-1, descending=True)\n",
    "    num_edges = sorted_S_flatten.count_nonzero(-1) #(bs, )\n",
    "    if relative_threshold:\n",
    "        to_keep_edge = torch.ceil(\n",
    "            num_edges * relative_threshold).to(torch.long)\n",
    "    threshold_score = sorted_S_flatten[range(\n",
    "        S_flatten.shape[0]), to_keep_edge] # (bs, )\n",
    "    A = (S_flatten > threshold_score.reshape(-1, 1)\n",
    "            ).float().reshape(S.shape) #(bs, max_step, max_step)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 4., 0.],\n",
       "         [0., 7., 9., 3.],\n",
       "         [0., 3., 0., 0.],\n",
       "         [0., 3., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0.],\n",
       "         [4., 0., 0., 4.],\n",
       "         [0., 0., 8., 0.],\n",
       "         [0., 0., 8., 0.]]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = torch.tensor([[[1, 2, 4, 0],\n",
    "                    [0, 7, 9, 3],\n",
    "                    [2, 3, 0, 2],\n",
    "                    [2, 3, 0, 2]],\n",
    "                    \n",
    "                    [[0, 0, 0, 0],\n",
    "                    [4, 2, 3, 4],\n",
    "                    [2, 3, 8, 2],\n",
    "                    [2, 3, 8, 2]]])\n",
    "mask = graph_sparsification(adj, relative_threshold=0.5)\n",
    "adj * mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.greater对应的pytorch可求导操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([3., 2.], requires_grad=True)\n",
    "b = torch.tensor([0., 1.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "t  = (a > b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 2.], requires_grad=True), tensor([0., 1.], requires_grad=True))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.gt(a , b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = 3\n",
    "(torch.ones(L, L, dtype=torch.float32) - torch.eye(L, dtype=torch.float32)) + torch.eye(L, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = torch.tensor([2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (seq_len-1).view(-1, 1).unsqueeze(-1).expand(len(seq_len), 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx.shape # (bs, 1, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [1, 1, 1, 1],\n",
       "        [2, 2, 2, 2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.arange(3).unsqueeze(-1).repeat(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
